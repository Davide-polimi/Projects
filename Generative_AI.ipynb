{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Davide-polimi/Projects/blob/main/Generative_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V31yal0bErK"
      },
      "source": [
        "# LIBRARY SETUP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "zznSHAR-aTVs",
        "outputId": "deb4f939-f587-4bb0-b178-8b73f285917f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: tensorflow 2.14.0\n",
            "Uninstalling tensorflow-2.14.0:\n",
            "  Successfully uninstalled tensorflow-2.14.0\n",
            "\u001b[33mWARNING: Skipping tensorflow-text as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-decision-forests as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping tf-keras as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting tensorflow==2.14.0\n",
            "  Using cached tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting numpy==1.25.2\n",
            "  Using cached numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Collecting protobuf==4.25.3\n",
            "  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting jax==0.4.20\n",
            "  Using cached jax-0.4.20-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting flax==0.7.2\n",
            "  Using cached flax-0.7.2-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting jaxlib==0.4.20\n",
            "  Using cached jaxlib-0.4.20-cp311-cp311-manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting optax==0.1.7\n",
            "  Using cached optax-0.1.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting scipy==1.11.4\n",
            "  Using cached scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting absl-py>=1.0.0 (from tensorflow==2.14.0)\n",
            "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting astunparse>=1.6.0 (from tensorflow==2.14.0)\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting flatbuffers>=23.5.26 (from tensorflow==2.14.0)\n",
            "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
            "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.14.0)\n",
            "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.14.0)\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
            "Collecting h5py>=2.9.0 (from tensorflow==2.14.0)\n",
            "  Using cached h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting libclang>=13.0.0 (from tensorflow==2.14.0)\n",
            "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting ml-dtypes==0.2.0 (from tensorflow==2.14.0)\n",
            "  Using cached ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting opt-einsum>=2.3.2 (from tensorflow==2.14.0)\n",
            "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting packaging (from tensorflow==2.14.0)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting setuptools (from tensorflow==2.14.0)\n",
            "  Using cached setuptools-80.7.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting six>=1.12.0 (from tensorflow==2.14.0)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting termcolor>=1.1.0 (from tensorflow==2.14.0)\n",
            "  Using cached termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow==2.14.0)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.14.0)\n",
            "  Using cached wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.14.0)\n",
            "  Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3 (from tensorflow==2.14.0)\n",
            "  Using cached grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting tensorboard<2.15,>=2.14 (from tensorflow==2.14.0)\n",
            "  Using cached tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Using cached tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras<2.15,>=2.14.0 (from tensorflow==2.14.0)\n",
            "  Using cached keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting msgpack (from flax==0.7.2)\n",
            "  Using cached msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting orbax-checkpoint (from flax==0.7.2)\n",
            "  Using cached orbax_checkpoint-0.11.13-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting tensorstore (from flax==0.7.2)\n",
            "  Using cached tensorstore-0.1.75-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting rich>=11.1 (from flax==0.7.2)\n",
            "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting PyYAML>=5.4.1 (from flax==0.7.2)\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting chex>=0.1.5 (from optax==0.1.7)\n",
            "  Using cached chex-0.1.89-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow==2.14.0)\n",
            "  Using cached wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "INFO: pip is looking at multiple versions of chex to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting chex>=0.1.5 (from optax==0.1.7)\n",
            "  Using cached chex-0.1.88-py3-none-any.whl.metadata (17 kB)\n",
            "  Using cached chex-0.1.87-py3-none-any.whl.metadata (17 kB)\n",
            "  Using cached chex-0.1.86-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting toolz>=0.9.0 (from chex>=0.1.5->optax==0.1.7)\n",
            "  Using cached toolz-1.0.0-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=11.1->flax==0.7.2)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting pygments<3.0.0,>=2.13.0 (from rich>=11.1->flax==0.7.2)\n",
            "  Using cached pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached google_auth-2.40.1-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting requests<3,>=2.21.0 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting werkzeug>=1.0.1 (from tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting etils[epath,epy] (from orbax-checkpoint->flax==0.7.2)\n",
            "  Using cached etils-1.12.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "INFO: pip is looking at multiple versions of orbax-checkpoint to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting orbax-checkpoint (from flax==0.7.2)\n",
            "  Using cached orbax_checkpoint-0.11.12-py3-none-any.whl.metadata (2.0 kB)\n",
            "  Using cached orbax_checkpoint-0.11.11-py3-none-any.whl.metadata (2.0 kB)\n",
            "  Using cached orbax_checkpoint-0.11.10-py3-none-any.whl.metadata (2.0 kB)\n",
            "  Using cached orbax_checkpoint-0.11.9-py3-none-any.whl.metadata (2.0 kB)\n",
            "  Using cached orbax_checkpoint-0.11.8-py3-none-any.whl.metadata (2.0 kB)\n",
            "  Using cached orbax_checkpoint-0.11.7-py3-none-any.whl.metadata (2.0 kB)\n",
            "  Using cached orbax_checkpoint-0.11.6-py3-none-any.whl.metadata (1.9 kB)\n",
            "INFO: pip is still looking at multiple versions of orbax-checkpoint to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached orbax_checkpoint-0.11.5-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Using cached orbax_checkpoint-0.11.4-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Using cached orbax_checkpoint-0.11.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Using cached orbax_checkpoint-0.11.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Using cached orbax_checkpoint-0.11.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached orbax_checkpoint-0.11.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Using cached orbax_checkpoint-0.10.3-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Using cached orbax_checkpoint-0.10.2-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Using cached orbax_checkpoint-0.10.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Using cached orbax_checkpoint-0.10.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "  Using cached orbax_checkpoint-0.9.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.9.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.8.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.7.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.6.4-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.6.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.6.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.6.1-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.6.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.23-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.22-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.21-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.19-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.18-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.17-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.16-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting nest_asyncio (from orbax-checkpoint->flax==0.7.2)\n",
            "  Using cached nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "INFO: pip is looking at multiple versions of tensorstore to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorstore (from flax==0.7.2)\n",
            "  Using cached tensorstore-0.1.74-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "  Using cached tensorstore-0.1.73-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "  Using cached tensorstore-0.1.72-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "  Using cached tensorstore-0.1.71-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "  Using cached tensorstore-0.1.69-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.68-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.67-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "INFO: pip is still looking at multiple versions of tensorstore to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached tensorstore-0.1.66-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.65-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.64-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.63-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.62-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached tensorstore-0.1.61-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.60-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.59-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.58-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.57-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.56-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.55-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.54-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.53-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.52-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.51-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.50-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.49-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "  Using cached tensorstore-0.1.48-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "  Using cached tensorstore-0.1.47-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "  Using cached tensorstore-0.1.46-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "  Using cached tensorstore-0.1.45-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting orbax-checkpoint (from flax==0.7.2)\n",
            "  Using cached orbax_checkpoint-0.5.15-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.14-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.13-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.12-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.11-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.10-py3-none-any.whl.metadata (1.8 kB)\n",
            "  Using cached orbax_checkpoint-0.5.9-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.5.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.5.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.5.6-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.5.5-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.5.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.5.3-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.5.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.5.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.5.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.4.8-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.4.7-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.4.6-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.4.5-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Using cached orbax_checkpoint-0.4.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1->flax==0.7.2)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting fsspec (from etils[epath,epy]->orbax-checkpoint->flax==0.7.2)\n",
            "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting importlib_resources (from etils[epath,epy]->orbax-checkpoint->flax==0.7.2)\n",
            "  Using cached importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting zipp (from etils[epath,epy]->orbax-checkpoint->flax==0.7.2)\n",
            "  Using cached zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow==2.14.0)\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Using cached tensorflow-2.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.9 MB)\n",
            "Using cached numpy-1.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Using cached jax-0.4.20-py3-none-any.whl (1.7 MB)\n",
            "Using cached flax-0.7.2-py3-none-any.whl (226 kB)\n",
            "Using cached jaxlib-0.4.20-cp311-cp311-manylinux2014_x86_64.whl (85.8 MB)\n",
            "Using cached optax-0.1.7-py3-none-any.whl (154 kB)\n",
            "Using cached scipy-1.11.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "Using cached ml_dtypes-0.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "Using cached absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
            "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Using cached chex-0.1.86-py3-none-any.whl (98 kB)\n",
            "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Using cached grpcio-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Using cached h5py-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "Using cached keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
            "Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Using cached PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "Using cached setuptools-80.7.1-py3-none-any.whl (1.2 MB)\n",
            "Using cached tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
            "Using cached tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "Using cached termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "Using cached msgpack-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (403 kB)\n",
            "Using cached tensorstore-0.1.45-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "Using cached orbax_checkpoint-0.4.4-py3-none-any.whl (123 kB)\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached google_auth-2.40.1-py2.py3-none-any.whl (216 kB)\n",
            "Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Using cached markdown-3.8-py3-none-any.whl (106 kB)\n",
            "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Using cached pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Using cached toolz-1.0.0-py3-none-any.whl (56 kB)\n",
            "Using cached werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "Using cached wheel-0.45.1-py3-none-any.whl (72 kB)\n",
            "Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Using cached charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Using cached etils-1.12.2-py3-none-any.whl (167 kB)\n",
            "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Using cached zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
            "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: libclang, flatbuffers, zipp, wrapt, wheel, urllib3, typing-extensions, toolz, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, six, setuptools, PyYAML, pygments, pyasn1, protobuf, packaging, opt-einsum, oauthlib, numpy, nest_asyncio, msgpack, mdurl, MarkupSafe, markdown, keras, importlib_resources, idna, grpcio, gast, fsspec, etils, charset-normalizer, certifi, cachetools, absl-py, werkzeug, tensorstore, scipy, rsa, requests, pyasn1-modules, ml-dtypes, markdown-it-py, h5py, google-pasta, astunparse, rich, requests-oauthlib, jaxlib, jax, google-auth, orbax-checkpoint, google-auth-oauthlib, chex, tensorboard, optax, tensorflow, flax\n",
            "  Attempting uninstall: libclang\n",
            "    Found existing installation: libclang 18.1.1\n",
            "    Uninstalling libclang-18.1.1:\n",
            "      Successfully uninstalled libclang-18.1.1\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: zipp\n",
            "    Found existing installation: zipp 3.21.0\n",
            "    Uninstalling zipp-3.21.0:\n",
            "      Successfully uninstalled zipp-3.21.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.45.1\n",
            "    Uninstalling wheel-0.45.1:\n",
            "      Successfully uninstalled wheel-0.45.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: toolz\n",
            "    Found existing installation: toolz 1.0.0\n",
            "    Uninstalling toolz-1.0.0:\n",
            "      Successfully uninstalled toolz-1.0.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 3.1.0\n",
            "    Uninstalling termcolor-3.1.0:\n",
            "      Successfully uninstalled termcolor-3.1.0\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.37.1\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.37.1:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.37.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.14.0\n",
            "    Uninstalling tensorflow-estimator-2.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.14.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 80.7.1\n",
            "    Uninstalling setuptools-80.7.1:\n",
            "      Successfully uninstalled setuptools-80.7.1\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pygments\n",
            "    Found existing installation: Pygments 2.19.1\n",
            "    Uninstalling Pygments-2.19.1:\n",
            "      Successfully uninstalled Pygments-2.19.1\n",
            "  Attempting uninstall: pyasn1\n",
            "    Found existing installation: pyasn1 0.6.1\n",
            "    Uninstalling pyasn1-0.6.1:\n",
            "      Successfully uninstalled pyasn1-0.6.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.3\n",
            "    Uninstalling protobuf-4.25.3:\n",
            "      Successfully uninstalled protobuf-4.25.3\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: oauthlib\n",
            "    Found existing installation: oauthlib 3.2.2\n",
            "    Uninstalling oauthlib-3.2.2:\n",
            "      Successfully uninstalled oauthlib-3.2.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: nest_asyncio\n",
            "    Found existing installation: nest-asyncio 1.6.0\n",
            "    Uninstalling nest-asyncio-1.6.0:\n",
            "      Successfully uninstalled nest-asyncio-1.6.0\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.1.0\n",
            "    Uninstalling msgpack-1.1.0:\n",
            "      Successfully uninstalled msgpack-1.1.0\n",
            "  Attempting uninstall: mdurl\n",
            "    Found existing installation: mdurl 0.1.2\n",
            "    Uninstalling mdurl-0.1.2:\n",
            "      Successfully uninstalled mdurl-0.1.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: markdown\n",
            "    Found existing installation: Markdown 3.8\n",
            "    Uninstalling Markdown-3.8:\n",
            "      Successfully uninstalled Markdown-3.8\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.14.0\n",
            "    Uninstalling keras-2.14.0:\n",
            "      Successfully uninstalled keras-2.14.0\n",
            "  Attempting uninstall: importlib_resources\n",
            "    Found existing installation: importlib_resources 6.5.2\n",
            "    Uninstalling importlib_resources-6.5.2:\n",
            "      Successfully uninstalled importlib_resources-6.5.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.71.0\n",
            "    Uninstalling grpcio-1.71.0:\n",
            "      Successfully uninstalled grpcio-1.71.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: etils\n",
            "    Found existing installation: etils 1.12.2\n",
            "    Uninstalling etils-1.12.2:\n",
            "      Successfully uninstalled etils-1.12.2\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.2\n",
            "    Uninstalling charset-normalizer-3.4.2:\n",
            "      Successfully uninstalled charset-normalizer-3.4.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.4.26\n",
            "    Uninstalling certifi-2025.4.26:\n",
            "      Successfully uninstalled certifi-2025.4.26\n",
            "  Attempting uninstall: cachetools\n",
            "    Found existing installation: cachetools 5.5.2\n",
            "    Uninstalling cachetools-5.5.2:\n",
            "      Successfully uninstalled cachetools-5.5.2\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.2.2\n",
            "    Uninstalling absl-py-2.2.2:\n",
            "      Successfully uninstalled absl-py-2.2.2\n",
            "  Attempting uninstall: werkzeug\n",
            "    Found existing installation: Werkzeug 3.1.3\n",
            "    Uninstalling Werkzeug-3.1.3:\n",
            "      Successfully uninstalled Werkzeug-3.1.3\n",
            "  Attempting uninstall: tensorstore\n",
            "    Found existing installation: tensorstore 0.1.45\n",
            "    Uninstalling tensorstore-0.1.45:\n",
            "      Successfully uninstalled tensorstore-0.1.45\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.9.1\n",
            "    Uninstalling rsa-4.9.1:\n",
            "      Successfully uninstalled rsa-4.9.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: pyasn1-modules\n",
            "    Found existing installation: pyasn1_modules 0.4.2\n",
            "    Uninstalling pyasn1_modules-0.4.2:\n",
            "      Successfully uninstalled pyasn1_modules-0.4.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.13.0\n",
            "    Uninstalling h5py-3.13.0:\n",
            "      Successfully uninstalled h5py-3.13.0\n",
            "  Attempting uninstall: google-pasta\n",
            "    Found existing installation: google-pasta 0.2.0\n",
            "    Uninstalling google-pasta-0.2.0:\n",
            "      Successfully uninstalled google-pasta-0.2.0\n",
            "  Attempting uninstall: astunparse\n",
            "    Found existing installation: astunparse 1.6.3\n",
            "    Uninstalling astunparse-1.6.3:\n",
            "      Successfully uninstalled astunparse-1.6.3\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 14.0.0\n",
            "    Uninstalling rich-14.0.0:\n",
            "      Successfully uninstalled rich-14.0.0\n",
            "  Attempting uninstall: requests-oauthlib\n",
            "    Found existing installation: requests-oauthlib 2.0.0\n",
            "    Uninstalling requests-oauthlib-2.0.0:\n",
            "      Successfully uninstalled requests-oauthlib-2.0.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.20\n",
            "    Uninstalling jaxlib-0.4.20:\n",
            "      Successfully uninstalled jaxlib-0.4.20\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.20\n",
            "    Uninstalling jax-0.4.20:\n",
            "      Successfully uninstalled jax-0.4.20\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.40.1\n",
            "    Uninstalling google-auth-2.40.1:\n",
            "      Successfully uninstalled google-auth-2.40.1\n",
            "  Attempting uninstall: orbax-checkpoint\n",
            "    Found existing installation: orbax-checkpoint 0.4.4\n",
            "    Uninstalling orbax-checkpoint-0.4.4:\n",
            "      Successfully uninstalled orbax-checkpoint-0.4.4\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: chex\n",
            "    Found existing installation: chex 0.1.86\n",
            "    Uninstalling chex-0.1.86:\n",
            "      Successfully uninstalled chex-0.1.86\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "  Attempting uninstall: optax\n",
            "    Found existing installation: optax 0.1.7\n",
            "    Uninstalling optax-0.1.7:\n",
            "      Successfully uninstalled optax-0.1.7\n",
            "  Attempting uninstall: flax\n",
            "    Found existing installation: flax 0.7.2\n",
            "    Uninstalling flax-0.7.2:\n",
            "      Successfully uninstalled flax-0.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "keras-hub 0.18.1 requires tensorflow-text; platform_system != \"Darwin\", which is not installed.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "tensorflow-hub 0.16.1 requires tf-keras>=2.14.1, which is not installed.\n",
            "dopamine-rl 4.1.2 requires tf-keras>=2.18.0, which is not installed.\n",
            "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.1 which is incompatible.\n",
            "bigframes 2.4.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "blosc2 3.3.2 requires numpy>=1.26, but you have numpy 1.25.2 which is incompatible.\n",
            "ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.3 which is incompatible.\n",
            "ibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.25.2 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.3 which is incompatible.\n",
            "langchain-core 0.3.59 requires packaging<25,>=23.2, but you have packaging 25.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 PyYAML-6.0.2 absl-py-2.2.2 astunparse-1.6.3 cachetools-5.5.2 certifi-2025.4.26 charset-normalizer-3.4.2 chex-0.1.86 etils-1.12.2 flatbuffers-25.2.10 flax-0.7.2 fsspec-2025.3.2 gast-0.6.0 google-auth-2.40.1 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.71.0 h5py-3.13.0 idna-3.10 importlib_resources-6.5.2 jax-0.4.20 jaxlib-0.4.20 keras-2.14.0 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.2.0 msgpack-1.1.0 nest_asyncio-1.6.0 numpy-1.25.2 oauthlib-3.2.2 opt-einsum-3.4.0 optax-0.1.7 orbax-checkpoint-0.4.4 packaging-25.0 protobuf-4.25.3 pyasn1-0.6.1 pyasn1-modules-0.4.2 pygments-2.19.1 requests-2.32.3 requests-oauthlib-2.0.0 rich-14.0.0 rsa-4.9.1 scipy-1.11.4 setuptools-80.7.1 six-1.17.0 tensorboard-2.14.1 tensorboard-data-server-0.7.2 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.37.1 tensorstore-0.1.45 termcolor-3.1.0 toolz-1.0.0 typing-extensions-4.13.2 urllib3-2.4.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.14.1 zipp-3.21.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "certifi",
                  "google",
                  "numpy",
                  "pkg_resources",
                  "setuptools",
                  "six",
                  "zipp"
                ]
              },
              "id": "826424538777456e9a73e2cabd62843d"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Uninstall preinstalled TensorFlow\n",
        "!pip uninstall -y tensorflow tensorflow-text tensorflow-decision-forests tf-keras\n",
        "\n",
        "# Installa le versioni desiderate (giÃ  fatto)\n",
        "!pip install tensorflow==2.14.0 \\\n",
        "             numpy==1.25.2 \\\n",
        "             protobuf==4.25.3 \\\n",
        "             jax==0.4.20 \\\n",
        "             flax==0.7.2 \\\n",
        "             jaxlib==0.4.20 \\\n",
        "             optax==0.1.7 \\\n",
        "             scipy==1.11.4 --force-reinstall\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "QDh7LB2fhkbK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "d7c355a8-b22a-4cbb-b85a-2ed6f8108c3b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Unable to convert function return value to a Python type! The signature was\n\t() -> handle",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ce4a21b0d2dc>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mflax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_typing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodule_util\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_module_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlazy_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyLoader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_LazyLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m# from tensorflow.python import keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;31m# from tensorflow.python.layers import layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaved_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/saved_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/builder.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# pylint: disable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder_impl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_SavedModelBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder_impl\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSavedModelBuilder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# pylint: enable=unused-import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/saved_model/builder_impl.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaved_model_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msaver_pb2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/dtypes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpywrap_ml_dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0m_np_bfloat16\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_ml_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbfloat16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0m_np_float8_e4m3fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_ml_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat8_e4m3fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0m_np_float8_e5m2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_ml_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat8_e5m2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Unable to convert function return value to a Python type! The signature was\n\t() -> handle"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy\n",
        "import jax\n",
        "import flax\n",
        "import jaxlib\n",
        "import optax\n",
        "import scipy\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
        "\n",
        "print(tf.__version__)\n",
        "print(np.__version__)\n",
        "print(scipy.__version__)\n",
        "print(jax.__version__)\n",
        "print(flax.__version__)\n",
        "print(jaxlib.__version__)\n",
        "print(optax.__version__)\n",
        "print(scipy.__version__)\n",
        "from IPython.display import display, Markdown,Image, clear_output\n",
        "from google.colab import output\n",
        "import tempfile\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeMwHyQoFOl5"
      },
      "outputs": [],
      "source": [
        "def plot_plate_3d(dimensions):\n",
        "    length = dimensions[\"length_mm\"]\n",
        "    width = dimensions[\"width_mm\"]\n",
        "    thickness = dimensions[\"thickness_mm\"]\n",
        "\n",
        "    # Coordinate bounds centered around origin\n",
        "    x0, x1 = -length / 2, length / 2\n",
        "    y0, y1 = -width / 2, width / 2\n",
        "    z0, z1 = -thickness / 2, thickness / 2\n",
        "\n",
        "    # Define 8 corners of the plate (centered at origin)\n",
        "    corners = np.array([\n",
        "        [x0, y0, z0],\n",
        "        [x1, y0, z0],\n",
        "        [x1, y1, z0],\n",
        "        [x0, y1, z0],\n",
        "        [x0, y0, z1],\n",
        "        [x1, y0, z1],\n",
        "        [x1, y1, z1],\n",
        "        [x0, y1, z1]\n",
        "    ])\n",
        "\n",
        "    # Define faces\n",
        "    faces = [\n",
        "        [corners[0], corners[1], corners[2], corners[3]],  # bottom\n",
        "        [corners[4], corners[5], corners[6], corners[7]],  # top\n",
        "        [corners[0], corners[1], corners[5], corners[4]],  # front\n",
        "        [corners[1], corners[2], corners[6], corners[5]],  # right\n",
        "        [corners[2], corners[3], corners[7], corners[6]],  # back\n",
        "        [corners[3], corners[0], corners[4], corners[7]]   # left\n",
        "    ]\n",
        "\n",
        "    fig = plt.figure(figsize=(6, 6))\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    for face in faces:\n",
        "        ax.add_collection3d(\n",
        "            Poly3DCollection([face], facecolors='gray', edgecolors='k', alpha=0.3)\n",
        "        )\n",
        "\n",
        "    # Axes adjustment\n",
        "    ax.set_box_aspect([length, width, thickness])\n",
        "    ax.view_init(elev=30, azim=45)\n",
        "    ax.set_axis_off()\n",
        "\n",
        "    # Add reference axes centered at (0,0,0)\n",
        "    arrow_len = max(length, width, thickness) * 0.6\n",
        "    ax.quiver(0, 0, 0, arrow_len, 0, 0, color='blue', arrow_length_ratio=0.05)\n",
        "    ax.text(arrow_len * 1.02, 0, 0, 'X', color='blue')\n",
        "    ax.quiver(0, 0, 0, 0, arrow_len, 0, color='blue', arrow_length_ratio=0.05)\n",
        "    ax.text(0, arrow_len * 1.02, 0, 'Y', color='blue')\n",
        "    ax.quiver(0, 0, 0, 0, 0, arrow_len, color='blue', arrow_length_ratio=0.05)\n",
        "    ax.text(0, 0, arrow_len, 'Z', color='blue')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    time.sleep(0.3)\n",
        "\n",
        "\n",
        "dimensions = {\n",
        "    \"length_mm\": 120.0,\n",
        "    \"width_mm\": 80.0,\n",
        "    \"thickness_mm\": 10.0\n",
        "}\n",
        "plot_plate_3d(dimensions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2qdn9ouFUcA"
      },
      "outputs": [],
      "source": [
        "def plot_cylinder_3d(dimensions):\n",
        "    radius = dimensions[\"diameter_mm\"] / 2\n",
        "    height = dimensions[\"height_mm\"]\n",
        "    n_points = 100\n",
        "    theta = np.linspace(0, 2 * np.pi, n_points)\n",
        "\n",
        "    # Coordinates for top and bottom circles\n",
        "    x = radius * np.cos(theta)\n",
        "    y = radius * np.sin(theta)\n",
        "    z_bottom = np.zeros_like(x)\n",
        "    z_top = np.ones_like(x) * height\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Side faces\n",
        "    for i in range(n_points - 1):\n",
        "        verts = [[\n",
        "            [x[i], y[i], 0],\n",
        "            [x[i + 1], y[i + 1], 0],\n",
        "            [x[i + 1], y[i + 1], height],\n",
        "            [x[i], y[i], height]\n",
        "        ]]\n",
        "        ax.add_collection3d(Poly3DCollection(verts, facecolors='gray', edgecolors='none', alpha=0.3))\n",
        "\n",
        "    # Closing the loop (last segment)\n",
        "    verts = [[\n",
        "        [x[-1], y[-1], 0],\n",
        "        [x[0], y[0], 0],\n",
        "        [x[0], y[0], height],\n",
        "        [x[-1], y[-1], height]\n",
        "    ]]\n",
        "    ax.add_collection3d(Poly3DCollection(verts, facecolors='gray', edgecolors='none', alpha=0.3))\n",
        "\n",
        "    # Top and bottom surfaces\n",
        "    # Bottom face â clean ring (no radial lines)\n",
        "    bottom_ring = [[x[i], y[i], 0] for i in range(n_points)]\n",
        "    ax.add_collection3d(Poly3DCollection([bottom_ring], facecolors='gray', edgecolors='k', alpha=0.3, closed=True))\n",
        "\n",
        "    # Top face â clean ring (no radial lines)\n",
        "    top_ring = [[x[i], y[i], height] for i in range(n_points)]\n",
        "    ax.add_collection3d(Poly3DCollection([top_ring], facecolors='gray', edgecolors='k', alpha=0.3, closed=True))\n",
        "\n",
        "    # Add X, Y, Z blue axes (arrows)\n",
        "    arrow_color = 'blue'\n",
        "    arrow_length = dimensions[\"diameter_mm\"] * 1.2  # 120% of cylinder diameter\n",
        "\n",
        "    # Z axis (vertical)\n",
        "    ax.quiver(0, 0, 0, 0, 0, arrow_length, color=arrow_color, arrow_length_ratio=0.05)\n",
        "    ax.text(0, 0, arrow_length * 1.02, 'Z', color=arrow_color)\n",
        "\n",
        "    # X axis (horizontal, right)\n",
        "    ax.quiver(0, 0, 0, arrow_length, 0, 0, color=arrow_color, arrow_length_ratio=0.05)\n",
        "    ax.text(arrow_length * 1.02, 0, 0, 'X', color=arrow_color)\n",
        "\n",
        "    # Y axis (horizontal, forward)\n",
        "    ax.quiver(0, 0, 0, 0, arrow_length, 0, color=arrow_color, arrow_length_ratio=0.05)\n",
        "    ax.text(0, arrow_length * 1.02, 0, 'Y', color=arrow_color)\n",
        "\n",
        "    # Set aspect ratio and view\n",
        "    ax.set_box_aspect([1, 1, height / radius])\n",
        "    ax.view_init(elev=30, azim=45)\n",
        "    ax.set_axis_off()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    time.sleep(0.3)\n",
        "\n",
        "\n",
        "dimensions = {\"diameter_mm\": 60.0, \"height_mm\": 100.0}\n",
        "plot_cylinder_3d(dimensions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XpJ5Q_1FarW"
      },
      "outputs": [],
      "source": [
        "def plot_gear_3d(dimensions):\n",
        "    num_teeth = dimensions[\"number_of_teeth\"]\n",
        "    outer_radius = dimensions[\"outer_diameter\"] / 2\n",
        "    root_radius = dimensions[\"root_diameter\"] / 2\n",
        "    top_width = dimensions[\"tooth_top_width\"]\n",
        "    base_width = dimensions[\"tooth_base_width\"]\n",
        "    tooth_height = dimensions[\"tooth_height\"]\n",
        "    thickness = dimensions[\"gear_thickness\"]\n",
        "    clearance_angle_deg = dimensions[\"tooth_clearance_angle\"]\n",
        "\n",
        "    angle_step = 2 * np.pi / num_teeth\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    for i in range(num_teeth):\n",
        "        angle = i * angle_step\n",
        "\n",
        "        r_base = root_radius\n",
        "        r_tip = outer_radius\n",
        "        center_base = np.array([r_base * np.cos(angle), r_base * np.sin(angle)])\n",
        "        center_tip = np.array([r_tip * np.cos(angle), r_tip * np.sin(angle)])\n",
        "\n",
        "        tangent = np.array([-np.sin(angle), np.cos(angle)])\n",
        "        tangent /= np.linalg.norm(tangent)\n",
        "\n",
        "        top_half = top_width / 2\n",
        "        base_half = base_width / 2\n",
        "\n",
        "        v0 = center_base - tangent * base_half\n",
        "        v1 = center_base + tangent * base_half\n",
        "        v2 = center_tip + tangent * top_half\n",
        "        v3 = center_tip - tangent * top_half\n",
        "\n",
        "        v0_up = np.append(v0, thickness)\n",
        "        v1_up = np.append(v1, thickness)\n",
        "        v2_up = np.append(v2, thickness)\n",
        "        v3_up = np.append(v3, thickness)\n",
        "\n",
        "        v0 = np.append(v0, 0)\n",
        "        v1 = np.append(v1, 0)\n",
        "        v2 = np.append(v2, 0)\n",
        "        v3 = np.append(v3, 0)\n",
        "\n",
        "        top_face = [v0, v1, v2, v3]\n",
        "        bottom_face = [v0_up, v1_up, v2_up, v3_up]\n",
        "        side1 = [v0, v0_up, v3_up, v3]\n",
        "        side2 = [v1, v1_up, v2_up, v2]\n",
        "        front = [v3, v2, v2_up, v3_up]\n",
        "\n",
        "        ax.add_collection3d(Poly3DCollection([top_face], facecolors='lightgray', edgecolors='none',alpha=0.3))\n",
        "        ax.add_collection3d(Poly3DCollection([bottom_face], facecolors='lightgray', edgecolors='none',alpha=0.3))\n",
        "        ax.add_collection3d(Poly3DCollection([side1], facecolors='gray', edgecolors='k',alpha=0.3))\n",
        "        ax.add_collection3d(Poly3DCollection([side2], facecolors='gray', edgecolors='k',alpha=0.3))\n",
        "        ax.add_collection3d(Poly3DCollection([front], facecolors='dimgray', edgecolors='k',alpha=0.3))\n",
        "\n",
        "    # Add central cylinder (solid disc)\n",
        "    n_circle = 100\n",
        "    theta = np.linspace(0, 2 * np.pi, n_circle)\n",
        "    r_inner = 0.0\n",
        "    r_outer = root_radius\n",
        "\n",
        "    # Lower circle (z = 0)\n",
        "    x_lower = r_outer * np.cos(theta)\n",
        "    y_lower = r_outer * np.sin(theta)\n",
        "    verts_lower = [[0, 0, 0]] + [[x, y, 0] for x, y in zip(x_lower, y_lower)]\n",
        "\n",
        "    # Upper circle (z = thickness)\n",
        "    x_upper = r_outer * np.cos(theta)\n",
        "    y_upper = r_outer * np.sin(theta)\n",
        "    verts_upper = [[0, 0, thickness]] + [[x, y, thickness] for x, y in zip(x_upper, y_upper)]\n",
        "\n",
        "    # Side wall of the cylinder\n",
        "    for i in range(n_circle - 1):\n",
        "        x0, y0 = x_lower[i], y_lower[i]\n",
        "        x1, y1 = x_lower[i + 1], y_lower[i + 1]\n",
        "        ax.add_collection3d(Poly3DCollection(\n",
        "            [[\n",
        "                [x0, y0, 0],\n",
        "                [x1, y1, 0],\n",
        "                [x1, y1, thickness],\n",
        "                [x0, y0, thickness]\n",
        "            ]],\n",
        "            facecolors='gray', edgecolors='none',alpha=0.3\n",
        "        ))\n",
        "\n",
        "    # Close the loop\n",
        "    x0, y0 = x_lower[-1], y_lower[-1]\n",
        "    x1, y1 = x_lower[0], y_lower[0]\n",
        "    ax.add_collection3d(Poly3DCollection(\n",
        "        [[\n",
        "            [x0, y0, 0],\n",
        "            [x1, y1, 0],\n",
        "            [x1, y1, thickness],\n",
        "            [x0, y0, thickness]\n",
        "        ]],\n",
        "        facecolors='gray', edgecolors='none',alpha=0.3\n",
        "    ))\n",
        "\n",
        "    # Create only the outer ring to avoid radial lines\n",
        "    ring_lower = [v[:3] for v in verts_lower[1:]]  # exclude center point [0, 0, 0]\n",
        "    ring_upper = [v[:3] for v in verts_upper[1:]]  # exclude center point [0, 0, height]\n",
        "\n",
        "    ax.add_collection3d(Poly3DCollection([ring_lower], facecolors='gray', edgecolors='k', alpha=0.3, closed=True))\n",
        "    ax.add_collection3d(Poly3DCollection([ring_upper], facecolors='gray', edgecolors='k', alpha=0.3, closed=True))\n",
        "\n",
        "    # Add custom blue arrows for X, Y, Z axes (20% longer than outer_diameter)\n",
        "    arrow_color = 'blue'\n",
        "\n",
        "    # Z axis (vertical)\n",
        "    ax.quiver(0, 0, 0, 0, 0, thickness *1.5, color=arrow_color, arrow_length_ratio=0.01)\n",
        "    ax.text(0, 0, thickness * 1.05, 'Z', color=arrow_color)\n",
        "\n",
        "    # X axis â radial, from center to first tooth base center (Î¸ = 0), scaled\n",
        "    theta0 = 0\n",
        "    r_base = dimensions[\"root_diameter\"] / 2\n",
        "    x_target = r_base * np.cos(theta0) * 1.5\n",
        "    y_target = r_base * np.sin(theta0) * 1.5\n",
        "    ax.quiver(0, 0, 0, x_target, y_target, 0, color=arrow_color, arrow_length_ratio=0.01)\n",
        "    ax.text(x_target * 1.02, y_target * 1.02, 0, 'X', color=arrow_color)\n",
        "\n",
        "    # Y axis â tangent to the pitch at Î¸ = 0, scaled\n",
        "    x_tangent = -np.sin(theta0) * r_base * 1.5\n",
        "    y_tangent =  np.cos(theta0) * r_base * 1.5\n",
        "    ax.quiver(0, 0, 0, x_tangent, y_tangent, 0, color=arrow_color, arrow_length_ratio=0.01)\n",
        "    ax.text(x_tangent * 1.02, y_tangent * 1.02, 0, 'Y', color=arrow_color)\n",
        "\n",
        "    ax.set_box_aspect([1, 1, 0.3])\n",
        "    ax.view_init(elev=30, azim=45)\n",
        "    ax.set_axis_off()\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Salva e mostra immagine\n",
        "    tmpfile = tempfile.NamedTemporaryFile(suffix='.png', delete=False)\n",
        "    plt.savefig(tmpfile.name)\n",
        "    plt.close(fig)\n",
        "\n",
        "    display(Image(tmpfile.name))\n",
        "    time.sleep(0.5)\n",
        "\n",
        "# Example gear dimensions\n",
        "dimensions = {\n",
        "    \"number_of_teeth\": 20,\n",
        "    \"outer_diameter\": 100.0,           # mm\n",
        "    \"root_diameter\": 80.0,             # mm\n",
        "    \"tooth_top_width\": 6.0,            # mm\n",
        "    \"tooth_base_width\": 10.0,          # mm\n",
        "    \"tooth_height\": (100 - 80) / 2,    # mm\n",
        "    \"gear_thickness\": 10.0,            # mm\n",
        "    \"tooth_clearance_angle\": 0.0       # degrees (not used in current version)\n",
        "}\n",
        "\n",
        "plot_gear_3d(dimensions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67Rh_ewmnLQO"
      },
      "source": [
        "# Text Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lOSf5bk6GM6"
      },
      "outputs": [],
      "source": [
        "def collect_part_info():\n",
        "    SUPPORTED_GEOMETRIES = [\"Plate\", \"Cylinder\", \"Gear\", \"Flange\", \"Bracket\", \"Block\"]\n",
        "    print(\"Fill in the following information about the part to be machined:\\n\")\n",
        "\n",
        "    material = input(\"Material: \")\n",
        "    print(\"Select the type of geometry:\")\n",
        "    for i, g in enumerate(SUPPORTED_GEOMETRIES):\n",
        "        print(f\"{i+1}. {g}\")\n",
        "\n",
        "    choice = int(input(\"Enter the corresponding number: \")) - 1\n",
        "    geometry = SUPPORTED_GEOMETRIES[choice]\n",
        "    dimensions = ask_dimensions(geometry)\n",
        "    origin = define_reference_origin(geometry, dimensions)\n",
        "    features = collect_features()\n",
        "    tolerance_val = input(\"Required tolerance Â± ... mm â Enter only the value: \")\n",
        "    tolerance = f\"Â±{tolerance_val} mm\"\n",
        "\n",
        "    finish_val = input(\"Surface finish Ra < ... Âµm â Enter only the value: \")\n",
        "    finish = f\"Ra < {finish_val} Âµm\"\n",
        "\n",
        "    part_info = {\n",
        "        \"geometry\": geometry,\n",
        "        \"geometry_parameters\": dimensions,\n",
        "        \"material\": material,\n",
        "        \"reference_origin\": origin,\n",
        "        \"features\": features,\n",
        "        \"tolerance\": tolerance,\n",
        "        \"surface_finish\": finish\n",
        "    }\n",
        "\n",
        "    print(\"\\nCollected information:\")\n",
        "    for k, v in part_info.items():\n",
        "        print(f\"- {k}: {v}\")\n",
        "\n",
        "    return part_info\n",
        "\n",
        "def ask_dimensions(geometry):\n",
        "    print(f\"\\nEnter the dimensional parameters for geometry: {geometry}\\n\")\n",
        "    dimensions = {}\n",
        "\n",
        "    if geometry == \"Plate\":\n",
        "        dimensions[\"length_mm\"] = float(input(\"Length (mm): \"))\n",
        "        dimensions[\"width_mm\"] = float(input(\"Width (mm): \"))\n",
        "        dimensions[\"thickness_mm\"] = float(input(\"Thickness (mm): \"))\n",
        "\n",
        "    elif geometry == \"Cylinder\":\n",
        "        dimensions[\"diameter_mm\"] = float(input(\"Diameter (mm): \"))\n",
        "        dimensions[\"height_mm\"] = float(input(\"Height (mm): \"))\n",
        "\n",
        "    elif geometry == \"Gear\":\n",
        "        print(\"\\n--- Define gear parameters ---\")\n",
        "        # Core parameters for trapezoidal gear shape\n",
        "        dimensions[\"number_of_teeth\"] = int(input(\"Number of teeth: \"))\n",
        "        dimensions[\"module\"] = float(input(\"Module (mm): \"))\n",
        "        dimensions[\"pressure_angle\"] = float(input(\"Pressure angle (degrees), typically 20: \"))\n",
        "\n",
        "        # Derived involute geometry\n",
        "        dimensions[\"pitch_diameter\"] = dimensions[\"module\"] * dimensions[\"number_of_teeth\"]\n",
        "        dimensions[\"addendum\"] = dimensions[\"module\"]\n",
        "        dimensions[\"dedendum\"] = 1.25 * dimensions[\"module\"]\n",
        "        dimensions[\"outer_diameter\"] = dimensions[\"pitch_diameter\"] + 2 * dimensions[\"addendum\"]\n",
        "        dimensions[\"root_diameter\"] = dimensions[\"pitch_diameter\"] - 2 * dimensions[\"dedendum\"]\n",
        "\n",
        "        # Useful for trapezoidal plotting\n",
        "        dimensions[\"tooth_height\"] = dimensions[\"outer_diameter\"] / 2 - dimensions[\"root_diameter\"] / 2\n",
        "        dimensions[\"tooth_top_width\"] = float(input(\"Tooth top width (Width of the trapezoid at the tip): \"))\n",
        "        dimensions[\"tooth_base_width\"] = float(input(\"Tooth base width (Width of the trapezoid at the base): \"))\n",
        "\n",
        "        # 3D extrusion\n",
        "        dimensions[\"gear_thickness\"] = float(input(\"Gear thickness (Extrusion depth in mm): \"))\n",
        "\n",
        "        # Optional manufacturing tolerance\n",
        "        dimensions[\"tooth_clearance_angle\"] = float(input(\"Tooth clearance angle (deg, optional, set 0 if not needed): \"))\n",
        "    elif geometry == \"Flange\":\n",
        "        dimensions[\"outer_diameter_mm\"] = float(input(\"Outer diameter (mm): \"))\n",
        "        dimensions[\"thickness_mm\"] = float(input(\"Thickness (mm): \"))\n",
        "        dimensions[\"number_of_holes\"] = int(input(\"Number of holes: \"))\n",
        "\n",
        "    elif geometry == \"Bracket\":\n",
        "        dimensions[\"width_mm\"] = float(input(\"Width (mm): \"))\n",
        "        dimensions[\"height_mm\"] = float(input(\"Height (mm): \"))\n",
        "        dimensions[\"thickness_mm\"] = float(input(\"Thickness (mm): \"))\n",
        "        dimensions[\"bend_angle_deg\"] = float(input(\"Bend angle (Â°): \"))\n",
        "\n",
        "    elif geometry == \"Block\":\n",
        "        dimensions[\"length_mm\"] = float(input(\"Length (mm): \"))\n",
        "        dimensions[\"width_mm\"] = float(input(\"Width (mm): \"))\n",
        "        dimensions[\"height_mm\"] = float(input(\"Height (mm): \"))\n",
        "\n",
        "    else:\n",
        "        print(\"Unrecognized geometry. No parameters required.\")\n",
        "\n",
        "    return dimensions\n",
        "\n",
        "def define_reference_origin(geometry, dimensions):\n",
        "    print(\"\\n--- DEFINITION OF THE ORIGIN AND AXES OF THE REFERENCE SYSTEM (WCS) ---\")\n",
        "    plot_reference_system(geometry, dimensions)\n",
        "\n",
        "    if geometry in [\"Plate\", \"Block\"]:\n",
        "        origin_descr = \"Center of the mid-plane\"\n",
        "        orientation_descr = \"X along the length direction, Y along the width direction, Z along thickness direction\"\n",
        "    elif geometry in [\"Cylinder\"]:\n",
        "        origin_descr = \"Center of the cylinder on the lower surface\"\n",
        "        orientation_descr = \"X radial, Y radial, Z along the cylinder axis (upwards)\"\n",
        "    elif geometry in [ \"Gear\", \"Flange\"]:\n",
        "        origin_descr = \"Center of the lower surface of the Gear\"\n",
        "        orientation_descr = \"X radial, Y radial, Z along the cylinder axis (upwards)\"\n",
        "    elif geometry == \"Bracket\":\n",
        "        origin_descr = \"Approximate center of the bent plane\"\n",
        "        orientation_descr = \"X along the base, Y along height, Z through thickness\"\n",
        "    else:\n",
        "        origin_descr = \"Estimated geometric center of the part\"\n",
        "        orientation_descr = \"X, Y, Z oriented according to neutral geometry (Cartesian)\"\n",
        "\n",
        "    print(f\"\\nSuggested origin: **{origin_descr}** â considered as (0, 0, 0)\")\n",
        "    print(f\"Default axis orientation: {orientation_descr}\")\n",
        "\n",
        "    choice = input(\"\\nDo you want to use this origin and orientation? (y = yes, n = no): \").strip().lower()\n",
        "\n",
        "    if choice == 'y':\n",
        "        return {\n",
        "            \"origin_mm\": [0.0, 0.0, 0.0],\n",
        "            \"origin_description\": origin_descr,\n",
        "            \"axis_orientation\": orientation_descr,\n",
        "            \"rotation_deg\": [0.0, 0.0, 0.0]\n",
        "        }\n",
        "\n",
        "    elif choice == 'n':\n",
        "        print(\"\\nEnter an offset from the suggested point (in mm):\")\n",
        "        x = float(input(\"Offset X: \"))\n",
        "        y = float(input(\"Offset Y: \"))\n",
        "        z = float(input(\"Offset Z: \"))\n",
        "        new_origin = [round(x, 2), round(y, 2), round(z, 2)]\n",
        "\n",
        "        rotation = [0.0, 0.0, 0.0]\n",
        "        rot_choice = input(\"Do you also want to rotate the reference system? (y/n): \").strip().lower()\n",
        "        if rot_choice == 'y':\n",
        "            print(\"Enter rotation angles around the axes (in degrees):\")\n",
        "            rx = float(input(\"Rotation around X (Â°): \"))\n",
        "            ry = float(input(\"Rotation around Y (Â°): \"))\n",
        "            rz = float(input(\"Rotation around Z (Â°): \"))\n",
        "            rotation = [round(rx, 2), round(ry, 2), round(rz, 2)]\n",
        "\n",
        "        return {\n",
        "            \"origin_mm\": new_origin,\n",
        "            \"origin_description\": f\"Offset origin relative to: {origin_descr}\",\n",
        "            \"axis_orientation\": orientation_descr,\n",
        "            \"rotation_deg\": rotation\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid answer. Using default values.\")\n",
        "        return {\n",
        "            \"origin_mm\": [0.0, 0.0, 0.0],\n",
        "            \"origin_description\": origin_descr,\n",
        "            \"axis_orientation\": orientation_descr,\n",
        "            \"rotation_deg\": [0.0, 0.0, 0.0]\n",
        "        }\n",
        "\n",
        "def define_machining_direction():\n",
        "    print(\"\\nDefinition of machining direction:\")\n",
        "    choice = input(\"Do you want to align machining to one of the main X/Y/Z axes? (y/n): \").strip().lower()\n",
        "\n",
        "    if choice == 'y':\n",
        "        axis = input(\"Specify the machining axis (X / Y / Z): \").strip().upper()\n",
        "        if axis in [\"X\", \"Y\", \"Z\"]:\n",
        "            return {\"type\": \"main_axis\", \"direction\": axis}\n",
        "        else:\n",
        "            print(\"Invalid axis. Using Z axis by default.\")\n",
        "            return {\"type\": \"main_axis\", \"direction\": \"Z\"}\n",
        "\n",
        "    elif choice == 'n':\n",
        "        print(\"Specify the inclined machining direction:\")\n",
        "        angle_xy = float(input(\"Angle in the XY plane w.r.t. X axis (degrees, clockwise): \"))\n",
        "        angle_z = float(input(\"Inclination angle w.r.t. Z axis (degrees, clockwise): \"))\n",
        "        return {\n",
        "            \"type\": \"inclined_direction\",\n",
        "            \"angle_xy_deg\": round(angle_xy, 2),\n",
        "            \"angle_z_deg\": round(angle_z, 2)\n",
        "        }\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid answer. Using Z axis by default.\")\n",
        "        return {\"type\": \"main_axis\", \"direction\": \"Z\"}\n",
        "\n",
        "def collect_features():\n",
        "    print(\"\\n--- GEOMETRIC FEATURE COLLECTION ---\")\n",
        "    features = []\n",
        "    count = 1\n",
        "\n",
        "    FEATURE_TYPES = {\n",
        "        \"1\": \"Through hole\",\n",
        "        \"2\": \"Blind hole\",\n",
        "        \"3\": \"Rectangular pocket\",\n",
        "        \"4\": \"Circular pocket\",\n",
        "        \"5\": \"Slot\",\n",
        "        \"6\": \"Chamfer\",\n",
        "        \"7\": \"Thread\",\n",
        "        \"8\": \"Other (free description)\"\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "        choice = input(f\"\\nDo you want to add feature #{count}? (y/n): \").strip().lower()\n",
        "        if choice == 'n':\n",
        "            break\n",
        "        elif choice != 'y':\n",
        "            print(\"Invalid response. Please enter 'y' or 'n'.\")\n",
        "            continue\n",
        "\n",
        "        print(\"\\nSelect the type of feature:\")\n",
        "        for code, name in FEATURE_TYPES.items():\n",
        "            print(f\"{code}. {name}\")\n",
        "        ftype = input(\"Number corresponding to the feature: \").strip()\n",
        "\n",
        "        if ftype not in FEATURE_TYPES:\n",
        "            print(\"Invalid feature type.\")\n",
        "            continue\n",
        "\n",
        "        feature = {\"type\": FEATURE_TYPES[ftype]}\n",
        "\n",
        "        if ftype == \"1\":  # Through hole\n",
        "            feature[\"diameter_mm\"] = float(input(\"Diameter (mm): \"))\n",
        "            x = float(input(\"Center X position (mm): \"))\n",
        "            y = float(input(\"Center Y position (mm): \"))\n",
        "            z = float(input(\"Center Z position (mm): \"))\n",
        "            feature[\"position_mm\"] = [x, y, z]\n",
        "            feature[\"machining_direction\"] = define_machining_direction()\n",
        "\n",
        "        elif ftype == \"2\":  # Blind hole\n",
        "            feature[\"diameter_mm\"] = float(input(\"Diameter (mm): \"))\n",
        "            feature[\"depth_mm\"] = float(input(\"Depth (mm): \"))\n",
        "            x = float(input(\"X position (mm): \"))\n",
        "            y = float(input(\"Y position (mm): \"))\n",
        "            z = float(input(\"Z position (mm): \"))\n",
        "            feature[\"position_mm\"] = [x, y, z]\n",
        "            feature[\"machining_direction\"] = define_machining_direction()\n",
        "\n",
        "        elif ftype == \"3\":  # Rectangular pocket\n",
        "            feature[\"length_mm\"] = float(input(\"Length (mm): \"))\n",
        "            feature[\"width_mm\"] = float(input(\"Width (mm): \"))\n",
        "            feature[\"depth_mm\"] = float(input(\"Depth (mm): \"))\n",
        "            x = float(input(\"X position (mm): \"))\n",
        "            y = float(input(\"Y position (mm): \"))\n",
        "            feature[\"position_mm\"] = [x, y]\n",
        "\n",
        "        elif ftype == \"4\":  # Circular pocket\n",
        "            feature[\"diameter_mm\"] = float(input(\"Diameter (mm): \"))\n",
        "            feature[\"depth_mm\"] = float(input(\"Depth (mm): \"))\n",
        "            x = float(input(\"X position (mm): \"))\n",
        "            y = float(input(\"Y position (mm): \"))\n",
        "            feature[\"position_mm\"] = [x, y]\n",
        "\n",
        "        elif ftype == \"5\":  # Slot\n",
        "            feature[\"length_mm\"] = float(input(\"Length (mm): \"))\n",
        "            feature[\"width_mm\"] = float(input(\"Width (mm): \"))\n",
        "            x = float(input(\"X position (mm): \"))\n",
        "            y = float(input(\"Y position (mm): \"))\n",
        "            feature[\"position_mm\"] = [x, y]\n",
        "\n",
        "        elif ftype == \"6\":  # Chamfer / Fillet\n",
        "            feature[\"radius_mm\"] = float(input(\"Radius (mm): \"))\n",
        "            feature[\"edge\"] = input(\"Edge to apply the feature (e.g., top edge, right edge...): \").strip()\n",
        "\n",
        "        elif ftype == \"7\":  # Thread\n",
        "            feature[\"nominal_diameter_mm\"] = float(input(\"Nominal diameter (mm): \"))\n",
        "            feature[\"pitch_mm\"] = float(input(\"Pitch (mm): \"))\n",
        "            feature[\"depth_mm\"] = float(input(\"Depth (mm): \"))\n",
        "            x = float(input(\"X position (mm): \"))\n",
        "            y = float(input(\"Y position (mm): \"))\n",
        "            feature[\"position_mm\"] = [x, y]\n",
        "\n",
        "        elif ftype == \"8\":  # Other\n",
        "            desc = input(\"Free description of the feature: \").strip()\n",
        "            if desc:\n",
        "                feature[\"description\"] = desc\n",
        "            else:\n",
        "                print(\"Empty description not valid. Feature ignored.\")\n",
        "                continue\n",
        "\n",
        "        features.append(feature)\n",
        "        count += 1\n",
        "\n",
        "    return features\n",
        "\n",
        "def plot_reference_system(geometry, dimensions):\n",
        "\n",
        "    if geometry == \"Gear\":\n",
        "        plot_gear_3d(dimensions)\n",
        "    elif geometry == \"Cylinder\":\n",
        "        plot_cylinder_3d(dimensions)\n",
        "    elif geometry == \"Plate\":\n",
        "        plot_plate_3d(dimensions)\n",
        "    # Aggiungi altri casi se servono\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EybHX9gb3acv"
      },
      "outputs": [],
      "source": [
        "53# Esegui la funzione per raccogliere input\n",
        "part_info = collect_part_info()\n",
        "\n",
        "# Esegui la funzione per raccogliere input\n",
        "print(\"-------------- PART DESCRIPTION -----------------------\")\n",
        "for k, v in part_info.items():\n",
        "        print(f\"- {k}: {v}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zeVct4Gmxa8b"
      },
      "outputs": [],
      "source": [
        "# PART INFO DEFAULT text\n",
        "part_info = {'geometry': 'Plate',\n",
        "             'geometry_parameters': {'length_mm': 200.0, 'width_mm': 100.0, 'thickness_mm': 20.0},\n",
        "             'material': 'aluminum',\n",
        "             'reference_origin': {'origin_mm': [0.0, 0.0, 0.0], 'origin_description': 'Center of the mid-plane', 'axis_orientation': 'X to the right, Y in depth, Z upwards', 'rotation_deg': [0.0, 0.0, 0.0]},\n",
        "             'features': [{'type': 'Rectangular pocket', 'length_mm': 10.0, 'width_mm': 10.0, 'depth_mm': 10.0, 'position_mm': [50.0, 0.0]},\n",
        "                          {'type': 'Through hole', 'diameter_mm': 5.0, 'position_mm': [50.0, 0.0], 'machining_direction': {'type': 'main_axis', 'direction': 'Z'}},\n",
        "                          {'type': 'Through hole', 'diameter_mm': 5.0, 'position_mm': [-50.0, 0.0], 'machining_direction': {'type': 'main_axis', 'direction': 'Z'}},\n",
        "                          {'type': 'Rectangular pocket', 'length_mm': 10.0, 'width_mm': 60.0, 'depth_mm': 5.0, 'position_mm': [-20.0, 0.0]},\n",
        "                          {'type': 'Chamfer', 'radius_mm': 6.0, 'edge': 'top edge'},\n",
        "                          {'type': 'Fillet', 'radius_mm': 5.0, 'edge': 'right edge'}],\n",
        "             'tolerance': 'Â±3 mm',\n",
        "             'surface_finish': 'Ra < 40 Âµm'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmFZPA3kFF_M"
      },
      "source": [
        "# LLM Call"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Environment and prompt setup**"
      ],
      "metadata": {
        "id": "SEj1B9WPqlF8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "woBXMoq5Gw7G",
        "outputId": "8b8011a2-327e-4ce4-911d-8108605da5f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.4.26)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (4.23.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from referencing>=0.28.4->jsonschema) (4.13.2)\n"
          ]
        }
      ],
      "source": [
        "# Installation\n",
        "!pip install tiktoken\n",
        "!pip install jsonschema\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "P0-c2nf_FJyL",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import tiktoken\n",
        "import json\n",
        "import re\n",
        "from jsonschema import validate, ValidationError\n",
        "# Get key\n",
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OpenAI_API')\n",
        "openai.api_key = openai_api_key\n",
        "ENGINE =   \"gpt-4o-mini\"\n",
        "\n",
        "\n",
        "# ------------------------------ OPERATIONS -------------------------------------\n",
        "operation_constraints = {\n",
        "    \"Drilling (Through Hole)\": {\n",
        "        \"rpm_max\": 6000,\n",
        "        \"max_depth\": 100,\n",
        "        \"max_tool_diameter\": 25,\n",
        "        \"note\": \"High torque required for deep holes\"\n",
        "    },\n",
        "    \"Drilling (Blind Hole)\": {\n",
        "        \"rpm_max\": 6000,\n",
        "        \"max_depth\": 80,\n",
        "        \"max_tool_diameter\": 20,\n",
        "        \"note\": \"Careful chip evacuation needed\"\n",
        "    },\n",
        "    \"Face Milling\": {\n",
        "        \"rpm_max\": 8000,\n",
        "        \"max_depth\": 5,\n",
        "        \"max_tool_diameter\": 50,\n",
        "        \"note\": \"Large diameter end mills\"\n",
        "    },\n",
        "    \"Slot Milling\": {\n",
        "        \"rpm_max\": 7000,\n",
        "        \"max_depth\": 20,\n",
        "        \"max_tool_diameter\": 16,\n",
        "        \"note\": \"Requires stable fixturing\"\n",
        "    },\n",
        "    \"Contour Milling\": {\n",
        "        \"rpm_max\": 7500,\n",
        "        \"max_depth\": 10,\n",
        "        \"max_tool_diameter\": 20,\n",
        "        \"note\": \"High precision finish\"\n",
        "    },\n",
        "    \"Threading\": {\n",
        "        \"rpm_max\": 3000,\n",
        "        \"max_feed\": 300,\n",
        "        \"max_tool_diameter\": 12,\n",
        "        \"note\": \"Use correct tap cycle\"\n",
        "    },\n",
        "    \"Boring\": {\n",
        "        \"rpm_max\": 5000,\n",
        "        \"max_depth\": 120,\n",
        "        \"max_tool_diameter\": 40,\n",
        "        \"note\": \"Requires boring head attachment\"\n",
        "    },\n",
        "    \"Reaming\": {\n",
        "        \"rpm_max\": 4000,\n",
        "        \"max_depth\": 50,\n",
        "        \"max_tool_diameter\": 18,\n",
        "        \"note\": \"Use coolant for finish\"\n",
        "    },\n",
        "    \"Chamfering\": {\n",
        "        \"rpm_max\": 10000,\n",
        "        \"max_depth\": 2,\n",
        "        \"max_tool_diameter\": 10,\n",
        "        \"note\": \"45-degree chamfer tools\"\n",
        "    },\n",
        "    \"Tapping\": {\n",
        "        \"rpm_max\": 2500,\n",
        "        \"max_depth\": 30,\n",
        "        \"max_tool_diameter\": 12,\n",
        "        \"note\": \"Synchronous spindle required\"\n",
        "    }\n",
        "}\n",
        "\n",
        "# ----------------------------------- TOOLS ---------------------------------------------------\n",
        "available_tools = [\n",
        "    {\"name\": \"Twist Drill\", \"diameter_mm\": list(range(2, 26))},\n",
        "    {\"name\": \"End Mill\", \"diameter_mm\": list(range(1, 51))},\n",
        "    {\"name\": \"Chamfer Mill\", \"diameter_mm\": [5, 10, 15, 20]},\n",
        "    {\"name\": \"Ball Nose End Mill\", \"diameter_mm\": [3, 6, 12, 16]},\n",
        "    {\"name\": \"Tapered End Mill\", \"diameter_mm\": [5, 10, 20]},\n",
        "    {\"name\": \"Reamer\", \"diameter_mm\": [6, 8, 10, 12, 16]},\n",
        "    {\"name\": \"Boring Head\", \"diameter_mm\": [20, 30, 40]},\n",
        "    {\"name\": \"Thread Tap\", \"diameter_mm\": [3, 4, 5, 6, 8, 10, 12]},\n",
        "    {\"name\": \"Countersink\", \"diameter_mm\": [8, 10, 12]},\n",
        "    {\"name\": \"Face Mill Cutter\", \"diameter_mm\": [50, 63, 80]}\n",
        "]\n",
        "\n",
        "# Operations & tools definitions\n",
        "\n",
        "system_message1 = (\n",
        "    \"You are a CNC expert. Your job is to analyze a part description and identify the required machining operations.\\n\"\n",
        "    \"You must:\\n\"\n",
        "    \"1. List ONLY the operations needed to manufacture the part.\\n\"\n",
        "    \"2. For each operation, select ONE suitable tool from the available tools list.\\n\"\n",
        "    \"3. Follow machine constraints: allowed operations, tools, RPM, and depth limits.\\n\\n\"\n",
        "    \"Available operations:\\n\"\n",
        "    + \"\\n\".join(f\"- {op}: {c['note']} (RPM â¤{c['rpm_max']}, Depth â¤{c.get('max_depth','N/A')}, Tool Ã â¤{c.get('max_tool_diameter','N/A')})\"\n",
        "                for op, c in operation_constraints.items())\n",
        "    + \"\\n\\nAvailable tools:\\n\"\n",
        "    + \"\\n\".join(f\"- {t['name']}, diameters: {t['diameter_mm']}\" for t in available_tools)\n",
        "    + \"\\n\\nRespond ONLY in valid JSON format with this structure:\\n\"\n",
        "    \"\"\"{\n",
        "     \"Operations\": [\n",
        "        {\n",
        "          \"Operation\": \"...\",\n",
        "          \"Tool\": \"...\",\n",
        "          \"Position\": \"...\",\n",
        "          \"RPM\": \"...\",\n",
        "          \"Depth\": \"...\",\n",
        "          \"Notes\": \"...\"\n",
        "        },\n",
        "        {....},\n",
        "        .\n",
        "        .\n",
        "        .\n",
        "      ]\n",
        "    }\"\"\"\n",
        ")\n",
        "\n",
        "def build_prompt1(data):\n",
        "    return f\"\\nHere is the part description:\\n{json.dumps(data, indent=2)}\"\n",
        "\n",
        "\n",
        "# Process plan & setup plan definitions\n",
        "\n",
        "system_message2 = (\n",
        "    \"You are a CNC process planner. Given a part description and a list of operations/tools, your job is to:\\n\"\n",
        "    \"1. Define a setup plan: number of setups, orientation, and fixturing for each setup.\\n\"\n",
        "    \"2. Propose an optimal sequence of operations (process plan) across the setups.\\n\"\n",
        "    \"3. Include RPM, feedrate and depth, considering material constraints.\\n\\n\"\n",
        "    \"Output format (valid JSON only):\\n\"\n",
        "    \"\"\"{\n",
        "      \"Setup plan\": [\n",
        "        {\n",
        "          \"Setup number\": 1,\n",
        "          \"Orientation\": \"...\",\n",
        "          \"Fixturing\": \"...\",\n",
        "          \"Notes\": \"...\"\n",
        "        },\n",
        "        ...\n",
        "      ],\n",
        "      \"Process plan\": [\n",
        "        {\n",
        "          \"Step number\": 1,\n",
        "          \"Setup number\": 1,\n",
        "          \"Operation\": \"...\",\n",
        "          \"Tool\": \"...\",\n",
        "          \"RPM\": ...,\n",
        "          \"Feed\": ...,\n",
        "          \"Depth\": ...,\n",
        "          \"Notes\": \"...\"\n",
        "        },\n",
        "        ...\n",
        "      ]\n",
        "    }\"\"\"\n",
        ")\n",
        "\n",
        "def build_prompt2(part_info, operations_output):\n",
        "    return (\n",
        "        f\"Part description:\\n{json.dumps(part_info, indent=2)}\\n\\n\"\n",
        "        f\"Operations and selected tools:\\n{json.dumps(operations_output['Operations'], indent=2)}\"\n",
        "    )\n",
        "\n",
        "# Call API\n",
        "def call_api(message):\n",
        "    try:\n",
        "        response = openai.chat.completions.create(\n",
        "            model=ENGINE,\n",
        "            messages=[{\"role\": \"user\", \"content\": message}],\n",
        "            temperature=0.8,\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "    except Exception as e:\n",
        "        print(f\"API call error: {e}\")\n",
        "        return None\n",
        "\n",
        "def clean_llm_json_response(text: str) -> str:\n",
        "    \"\"\"\n",
        "    Pulisce l'output dell'LLM rimuovendo delimitatori ```json e ```\n",
        "    Rende il testo compatibile con json.loads()\n",
        "    \"\"\"\n",
        "    lines = text.strip().splitlines()\n",
        "    # Rimuovi tutte le righe che iniziano con ```\n",
        "    lines = [line for line in lines if not line.strip().startswith(\"```\")]\n",
        "    return \"\\n\".join(lines).strip()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Validation**"
      ],
      "metadata": {
        "id": "tE03voz1qu3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "from collections import defaultdict\n",
        "\n",
        "# Link between operations and tools\n",
        "operation_to_tool_type = {\n",
        "    \"Drilling (Through Hole)\": {\"Twist Drill\"},\n",
        "    \"Drilling (Blind Hole)\": {\"Twist Drill\"},\n",
        "    \"Face Milling\": {\"Face Mill Cutter\", \"End Mill\"},\n",
        "    \"Slot Milling\": {\"End Mill\", \"Ball Nose End Mill\"},\n",
        "    \"Contour Milling\": {\"End Mill\", \"Ball Nose End Mill\", \"Tapered End Mill\"},\n",
        "    \"Chamfering\": {\"Chamfer Mill\", \"Countersink\"},\n",
        "    \"Tapping\": {\"Thread Tap\"},\n",
        "    \"Threading\": {\"Thread Tap\"},\n",
        "    \"Boring\": {\"Boring Head\"},\n",
        "    \"Reaming\": {\"Reamer\"},\n",
        "}\n",
        "\n",
        "\n",
        "# Each tuple means: the first operation (A) must appear\n",
        "# BEFORE every occurrence of the second operation (B) within the same Setup.\n",
        "precedence_rules = [\n",
        "    # Hole finishing chain\n",
        "    (\"Drilling\",  \"Boring\"),      # pilot drill â bore to size\n",
        "    (\"Drilling\",  \"Reaming\"),     # drill â ream for tolerance\n",
        "    (\"Drilling\",  \"Tapping\"),     # drill â tap internal thread\n",
        "    (\"Drilling\",  \"Threading\"),   # drill â single-point thread\n",
        "\n",
        "    (\"Boring\",    \"Reaming\"),     # bore â ream (fine)\n",
        "\n",
        "    # Planar rough/finish chain\n",
        "    (\"Face Milling\",   \"Contour Milling\"),  # rough face â finish contour\n",
        "    (\"Face Milling\",   \"Slot Milling\"),     # rough face â cut slot\n",
        "    (\"Face Milling\",   \"Chamfering\"),       # rough face â chamfer edges\n",
        "    (\"Slot Milling\",   \"Chamfering\"),       # cut slot â chamfer slot edges\n",
        "\n",
        "    # Always-last rule\n",
        "    (\"Any\",      \"Chamfering\"),   # chamfer is one of the final ops\n",
        "]\n",
        "\n",
        "def op_category(op_name: str) -> str:\n",
        "    \"\"\"\n",
        "    Converts full operation label to a category keyword\n",
        "    used in the precedence rules above.\n",
        "    \"\"\"\n",
        "    if \"Drilling\" in op_name:  return \"Drilling\"\n",
        "    if \"Boring\"   in op_name:  return \"Boring\"\n",
        "    if \"Reaming\"  in op_name:  return \"Reaming\"\n",
        "    if \"Tapping\"  in op_name:  return \"Tapping\"\n",
        "    if \"Threading\" in op_name: return \"Threading\"\n",
        "    if \"Face Milling\" in op_name:   return \"Face Milling\"\n",
        "    if \"Slot Milling\" in op_name:   return \"Slot Milling\"\n",
        "    if \"Contour Milling\" in op_name: return \"Contour Milling\"\n",
        "    if \"Chamfering\" in op_name:     return \"Chamfering\"\n",
        "    # fallback: return the name itself\n",
        "    return op_name\n",
        "\n",
        "def validate_precedence(process_plan: List[Dict]) -> Tuple[bool, str]:\n",
        "    \"\"\"\n",
        "    Checks precedence rules within each Setup number.\n",
        "    Returns (is_valid, error_string)\n",
        "    \"\"\"\n",
        "    # Group steps by Setup number\n",
        "    steps_by_setup = defaultdict(list)\n",
        "    for step in process_plan:\n",
        "        steps_by_setup[step[\"Setup number\"]].append(step)\n",
        "\n",
        "    errors = []\n",
        "\n",
        "    # Walk each setup independently\n",
        "    for setup_no, steps in steps_by_setup.items():\n",
        "        # Ensure natural order by Step number\n",
        "        steps_sorted = sorted(steps, key=lambda s: s[\"Step number\"])\n",
        "        seen = set()                               # categories already executed\n",
        "\n",
        "        for step in steps_sorted:\n",
        "            idx = step[\"Step number\"]\n",
        "            cat = op_category(step[\"Operation\"])\n",
        "\n",
        "            # Check every rule whose B matches current category\n",
        "            for A, B in precedence_rules:\n",
        "                if (B == \"Any\") or (B == cat):\n",
        "                    # For 'Any' rule we test only if B is 'Chamfering'\n",
        "                    if B == \"Chamfering\" and cat != \"Chamfering\":\n",
        "                        continue\n",
        "\n",
        "                    # -------- precedence violation cases --------\n",
        "                    if A != \"Any\" and A not in seen:\n",
        "                        errors.append(\n",
        "                            f\"Setup {setup_no}, Step {idx}: '{cat}' \"\n",
        "                            f\"appears before any '{A}'.\"\n",
        "                        )\n",
        "                    if A == \"Any\" and cat == \"Chamfering\" and idx != steps_sorted[-1][\"Step number\"]:\n",
        "                        errors.append(\n",
        "                            f\"Setup {setup_no}, Step {idx}: Chamfering should be last in its setup.\"\n",
        "                        )\n",
        "\n",
        "            # Record that this category is now done\n",
        "            seen.add(cat)\n",
        "\n",
        "    if errors:\n",
        "        return False, \"\\n\".join(errors)\n",
        "\n",
        "    return True, \"\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def validate_call1(response_1: str) -> Tuple[bool, str]:\n",
        "    try:\n",
        "        data = json.loads(response_1)\n",
        "        operations = data.get(\"Operations\", [])\n",
        "    except json.JSONDecodeError as e:\n",
        "        return False, f\"â JSON parsing error: {e}\"\n",
        "\n",
        "    errors = []\n",
        "\n",
        "    # Valid operations from constraints\n",
        "    valid_operations = set(operation_constraints.keys())\n",
        "\n",
        "    # Tool dictionary: tool name â set of available diameters\n",
        "    tool_dict = {tool[\"name\"]: set(tool[\"diameter_mm\"]) for tool in available_tools}\n",
        "\n",
        "    for idx, op in enumerate(operations, 1):\n",
        "        op_name = op.get(\"Operation\", \"\").strip()\n",
        "        tool_str = op.get(\"Tool\", \"\").strip()\n",
        "\n",
        "        # ----- Check 1: Operation exists -----\n",
        "        if op_name not in valid_operations:\n",
        "            errors.append(f\"â Step #{idx}: '{op_name}' is not a supported operation.\")\n",
        "            continue  # Skip further checks for this operation\n",
        "\n",
        "        # ----- Check 2: Tool format -----\n",
        "        match = re.match(r\"(.+?),\\s*diameter[:\\s]*([0-9]+)\", tool_str)\n",
        "        if not match:\n",
        "            errors.append(f\"â Step #{idx}: Tool format invalid â '{tool_str}' (expected 'Tool Name, diameter: N')\")\n",
        "            continue\n",
        "\n",
        "        tool_name = match.group(1).strip()\n",
        "        try:\n",
        "            tool_diameter = int(match.group(2))\n",
        "        except ValueError:\n",
        "            errors.append(f\"â Step #{idx}: Tool diameter is not a valid integer â '{tool_str}'\")\n",
        "            continue\n",
        "\n",
        "        # ----- Check 3: Tool exists -----\n",
        "        if tool_name not in tool_dict:\n",
        "            errors.append(f\"â Step #{idx}: Tool '{tool_name}' is not in available tool list.\")\n",
        "            continue\n",
        "\n",
        "        # ----- Check 4: Diameter is allowed -----\n",
        "        if tool_diameter not in tool_dict[tool_name]:\n",
        "            valid_sizes = \", \".join(map(str, sorted(tool_dict[tool_name])))\n",
        "            errors.append(f\"â Step #{idx}: Tool '{tool_name}' does not support Ã{tool_diameter}. Valid: [{valid_sizes}]\")\n",
        "\n",
        "        # ----- Check 5: Tool type matches operation type -----\n",
        "        valid_tools_for_op = operation_to_tool_type.get(op_name, set())\n",
        "        if tool_name not in valid_tools_for_op:\n",
        "            valid_tool_list = \", \".join(valid_tools_for_op) if valid_tools_for_op else \"N/A\"\n",
        "            errors.append(\n",
        "                f\"â Step #{idx}: Tool '{tool_name}' is not valid for operation '{op_name}'. Expected one of: [{valid_tool_list}]\"\n",
        "            )\n",
        "\n",
        "    # ----- Return result -----\n",
        "    if errors:\n",
        "        error_msg = \"\\n\".join(errors)\n",
        "        return False, error_msg\n",
        "\n",
        "    return True, \"\"\n",
        "\n",
        "\n",
        "def validate_call2(response_2: str) -> Tuple[bool, str]:\n",
        "    try:\n",
        "        data = json.loads(response_2)\n",
        "        process_plan = data.get(\"Process plan\", [])\n",
        "    except json.JSONDecodeError as e:\n",
        "        return False, f\"â JSON parsing error: {e}\"\n",
        "\n",
        "    errors = []\n",
        "\n",
        "    for step in process_plan:\n",
        "        step_num = step.get(\"Step number\", \"?\")\n",
        "        operation = step.get(\"Operation\", \"\").strip()\n",
        "        rpm = step.get(\"RPM\", \"\")\n",
        "        depth = step.get(\"Depth\", \"\")\n",
        "        tool_str = step.get(\"Tool\", \"\").strip()\n",
        "\n",
        "        # --------- Check 1: operation must exist ---------\n",
        "        if operation not in operation_constraints:\n",
        "            errors.append(f\"â Step #{step_num}: Unknown operation '{operation}'\")\n",
        "            continue  # Skip parameter checks\n",
        "\n",
        "        op_constraints = operation_constraints[operation]\n",
        "\n",
        "        # --------- Check 2: RPM limit ---------\n",
        "        if \"rpm_max\" in op_constraints:\n",
        "            try:\n",
        "                rpm_val = float(rpm)\n",
        "                if rpm_val > op_constraints[\"rpm_max\"]:\n",
        "                    errors.append(\n",
        "                        f\"â Step #{step_num}: RPM {rpm_val} exceeds max RPM ({op_constraints['rpm_max']}) for '{operation}'\"\n",
        "                    )\n",
        "            except ValueError:\n",
        "                errors.append(f\"â Step #{step_num}: RPM '{rpm}' is not a valid number\")\n",
        "\n",
        "        # --------- Check 3: Depth limit ---------\n",
        "        if \"max_depth\" in op_constraints:\n",
        "            try:\n",
        "                depth_val = float(depth)\n",
        "                if depth_val > op_constraints[\"max_depth\"]:\n",
        "                    errors.append(\n",
        "                        f\"â Step #{step_num}: Depth {depth_val} exceeds max depth ({op_constraints['max_depth']}) for '{operation}'\"\n",
        "                    )\n",
        "            except ValueError:\n",
        "                errors.append(f\"â Step #{step_num}: Depth '{depth}' is not a valid number\")\n",
        "\n",
        "        # --------- Check 4: Tool diameter limit ---------\n",
        "        if \"max_tool_diameter\" in op_constraints:\n",
        "            match = re.search(r\"diameter[:\\s]*([0-9]+)\", tool_str)\n",
        "            if match:\n",
        "                try:\n",
        "                    tool_diameter = int(match.group(1))\n",
        "                    if tool_diameter > op_constraints[\"max_tool_diameter\"]:\n",
        "                        errors.append(\n",
        "                            f\"â Step #{step_num}: Tool Ã{tool_diameter} exceeds max Ã{op_constraints['max_tool_diameter']} for '{operation}'\"\n",
        "                        )\n",
        "                except ValueError:\n",
        "                    errors.append(f\"â Step #{step_num}: Invalid tool diameter in '{tool_str}'\")\n",
        "            else:\n",
        "                errors.append(f\"â Step #{step_num}: Tool diameter not found in '{tool_str}'\")\n",
        "\n",
        "        # --------- Check Order Consistency ---------\n",
        "        seq_ok, seq_errors = validate_precedence(process_plan)\n",
        "        if not seq_ok:\n",
        "            errors.append(seq_errors)\n",
        "\n",
        "    if errors:\n",
        "        return False, \"\\n\".join(errors)\n",
        "\n",
        "    return True, \"\"\n",
        "\n",
        "def validate_loop(response_1: str, response_2: str) -> bool:\n",
        "    try:\n",
        "        data1 = json.loads(response_1)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"â Call 1 JSON error: {e}\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        data2 = json.loads(response_2)\n",
        "    except json.JSONDecodeError as e:\n",
        "        print(f\"â Call 2 JSON error: {e}\")\n",
        "        return False\n",
        "\n",
        "    # --- Check response_1 minimal structure ---\n",
        "    if \"Operations\" not in data1 or not isinstance(data1[\"Operations\"], list):\n",
        "        print(\"â Call 1 is missing 'Operations' or it's not a list.\")\n",
        "        return False\n",
        "\n",
        "    if not data1[\"Operations\"]:\n",
        "        print(\"â Call 1: 'Operations' list is empty.\")\n",
        "        return False\n",
        "\n",
        "    # --- Check response_2 minimal structure ---\n",
        "    if \"Setup plan\" not in data2 or not isinstance(data2[\"Setup plan\"], list):\n",
        "        print(\"â Call 2 is missing 'Setup plan' or it's not a list.\")\n",
        "        return False\n",
        "\n",
        "    if \"Process plan\" not in data2 or not isinstance(data2[\"Process plan\"], list):\n",
        "        print(\"â Call 2 is missing 'Process plan' or it's not a list.\")\n",
        "        return False\n",
        "\n",
        "    if not data2[\"Process plan\"]:\n",
        "        print(\"â Call 2: 'Process plan' list is empty.\")\n",
        "        return False\n",
        "\n",
        "    # --- Passed fallback checks ---\n",
        "    print(\"â validate_loop: minimal required structure present in both responses.\")\n",
        "    return True\n"
      ],
      "metadata": {
        "id": "aeAQy9DurA7T"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LLM call loop**"
      ],
      "metadata": {
        "id": "ooDkRuBcrBmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_loop_correct = False\n",
        "is_call1_correct = False\n",
        "is_call2_correct = False\n",
        "count_loop = 0\n",
        "count_call1 = 0\n",
        "count_call2 = 0\n",
        "max_loop = 3\n",
        "max_call1 = 3\n",
        "max_call2 = 3\n",
        "\n",
        "# Main loop: repeats the entire process until both calls are valid or max attempts are reached\n",
        "while not is_loop_correct and count_loop < max_loop:\n",
        "    count_loop += 1\n",
        "    print(f\"ð Loop {count_loop}/{max_loop}\")\n",
        "\n",
        "    # ------------------- FIRST LLM CALL: OPERATIONS and TOOLS SELECTION ----------------------\n",
        "    while not is_call1_correct and count_call1 < max_call1:\n",
        "        count_call1 += 1\n",
        "        print(f\"ð Call 1 (Setup plan) {count_call1}/{max_call1}\")\n",
        "\n",
        "        # Compose the full message for the LLM (system message + user prompt)\n",
        "        message1 = system_message1 + build_prompt1(part_info)\n",
        "        # Call the LLM API and receive the raw response\n",
        "        response_1 = call_api(message1)\n",
        "        # Clean the LLM response to remove markdown formatting like ```json\n",
        "        response_1 = clean_llm_json_response(response_1)\n",
        "\n",
        "        # Validate the response\n",
        "        is_call1_correct, error_1 = validate_call1(response_1)\n",
        "        # If max attempts are reached without success, stop trying\n",
        "        if not is_call1_correct and count_call1 == max_call1:\n",
        "            print(\"â Call 1 failed after maximum attempts. Exiting.\")\n",
        "            print(error_1)\n",
        "            break\n",
        "        elif not is_call1_correct:\n",
        "            print(\"â Call 1 failed. Retrying...\")\n",
        "            message1 = system_message1 + build_prompt1(part_info) + error_1\n",
        "            print(error_1)\n",
        "        else:\n",
        "            print(\"â Call 1 ok.\")\n",
        "\n",
        "    # ---------------------- SECOND LLM CALL: SETUP and PROCESS PLAN ----------------------\n",
        "    while not is_call2_correct and count_call2 < max_call2:\n",
        "        count_call2 += 1\n",
        "        print(f\"ð Call 2 (Process plan) {count_call2}/{max_call2}\")\n",
        "\n",
        "        # Try to parse response_1\n",
        "        try:\n",
        "            parsed_response_1 = json.loads(response_1)\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(\"â JSON decoding error in response_1:\", e)\n",
        "            break\n",
        "\n",
        "        # Compose the full message for the second call, using the result of call 1\n",
        "        message2 = system_message2 + build_prompt2(part_info, parsed_response_1)\n",
        "\n",
        "        # Call the LLM API\n",
        "        response_2 = call_api(message2)\n",
        "\n",
        "        # Clean markdown formatting from response\n",
        "        response_2 = clean_llm_json_response(response_2)\n",
        "\n",
        "        # Validate the second response\n",
        "        is_call2_correct, error_2 = validate_call2(response_2)\n",
        "\n",
        "        # If max attempts are reached without success, stop trying\n",
        "        if not is_call2_correct and count_call2 == max_call2:\n",
        "            print(\"â Call 2 failed after maximum attempts. Exiting.\")\n",
        "            print(error_2)\n",
        "            break\n",
        "        elif not is_call2_correct:\n",
        "            print(\"â Call 2 failed. Retrying...\")\n",
        "            message2 = system_message2 + build_prompt2(part_info,json.loads(response_1)) + error_2\n",
        "            print(error_2)\n",
        "        else:\n",
        "            print(\"â Call 2 ok.\")\n",
        "\n",
        "    # ---------------------- FINAL VALIDATION: COMPLETE PLAN ----------------------\n",
        "    if is_call1_correct and is_call2_correct:\n",
        "        # Optional final validation for the combined output\n",
        "        is_loop_correct = validate_loop(response_1, response_2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Call 1\n",
        "# # print(system_message1)\n",
        "# # print(build_prompt1(part_info))\n",
        "# message1 = system_message1 + build_prompt1(part_info)\n",
        "# response_1 = call_api(message1)\n",
        "\n",
        "# response_1 = clean_llm_json_response(response_1)\n",
        "# print(response_1)\n",
        "# print(\"\\n\")\n",
        "# print(\"\\n\")\n",
        "# # # Call 2\n",
        "# # print(system_message2)\n",
        "# # print(build_prompt2(part_info,json.loads(response_1)))\n",
        "# message2 = system_message2 + build_prompt2(part_info, json.loads(response_1))\n",
        "# response_2 = call_api(message2)\n",
        "# response_2 = clean_llm_json_response(response_2)\n",
        "# print(response_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SFNWLeVrBNC",
        "outputId": "bdbf63b9-2e65-40ad-b442-cc74472573ee"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ð Loop 1/3\n",
            "ð Call 1 (Setup plan) 1/3\n",
            "â Call 1 failed. Retrying...\n",
            "â Step #1: Tool format invalid â 'End Mill, Ã 10' (expected 'Tool Name, diameter: N')\n",
            "â Step #2: Tool format invalid â 'Twist Drill, Ã 5' (expected 'Tool Name, diameter: N')\n",
            "â Step #3: Tool format invalid â 'Twist Drill, Ã 5' (expected 'Tool Name, diameter: N')\n",
            "â Step #4: Tool format invalid â 'End Mill, Ã 10' (expected 'Tool Name, diameter: N')\n",
            "â Step #5: Tool format invalid â 'Chamfer Mill, Ã 10' (expected 'Tool Name, diameter: N')\n",
            "â Step #6: Tool format invalid â 'Ball Nose End Mill, Ã 6' (expected 'Tool Name, diameter: N')\n",
            "ð Call 1 (Setup plan) 2/3\n",
            "â Call 1 failed. Retrying...\n",
            "â Step #1: Tool format invalid â 'End Mill, Ã 10' (expected 'Tool Name, diameter: N')\n",
            "â Step #2: Tool format invalid â 'Twist Drill, Ã 5' (expected 'Tool Name, diameter: N')\n",
            "â Step #3: Tool format invalid â 'Twist Drill, Ã 5' (expected 'Tool Name, diameter: N')\n",
            "â Step #4: Tool format invalid â 'End Mill, Ã 10' (expected 'Tool Name, diameter: N')\n",
            "â Step #5: Tool format invalid â 'Chamfer Mill, Ã 10' (expected 'Tool Name, diameter: N')\n",
            "â Step #6: Tool format invalid â 'Ball Nose End Mill, Ã 6' (expected 'Tool Name, diameter: N')\n",
            "ð Call 1 (Setup plan) 3/3\n",
            "â Call 1 failed after maximum attempts. Exiting.\n",
            "â Step #1: Tool format invalid â 'End Mill' (expected 'Tool Name, diameter: N')\n",
            "â Step #2: Tool format invalid â 'Twist Drill 5' (expected 'Tool Name, diameter: N')\n",
            "â Step #3: Tool format invalid â 'Twist Drill 5' (expected 'Tool Name, diameter: N')\n",
            "â Step #4: Tool format invalid â 'End Mill' (expected 'Tool Name, diameter: N')\n",
            "â Step #5: Tool format invalid â 'Chamfer Mill 10' (expected 'Tool Name, diameter: N')\n",
            "â Step #6: 'Fillet Milling' is not a supported operation.\n",
            "ð Call 2 (Process plan) 1/3\n",
            "â Call 2 failed. Retrying...\n",
            "â Step #1: Tool diameter not found in 'End Mill'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #2: Tool diameter not found in 'Twist Drill 5'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #3: Tool diameter not found in 'Twist Drill 5'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #4: Tool diameter not found in 'End Mill'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #5: Tool diameter not found in 'Chamfer Mill 10'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #6: Unknown operation 'Fillet Milling'\n",
            "ð Call 2 (Process plan) 2/3\n",
            "â Call 2 failed. Retrying...\n",
            "â Step #1: Tool diameter not found in 'End Mill'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #2: Tool diameter not found in 'Twist Drill 5'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #3: Tool diameter not found in 'Twist Drill 5'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #4: Tool diameter not found in 'End Mill'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #5: Tool diameter not found in 'Chamfer Mill 10'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #6: Unknown operation 'Fillet Milling'\n",
            "ð Call 2 (Process plan) 3/3\n",
            "â Call 2 failed after maximum attempts. Exiting.\n",
            "â Step #1: Tool diameter not found in 'End Mill'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #2: Tool diameter not found in 'Twist Drill 5'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #3: Tool diameter not found in 'Twist Drill 5'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #4: Tool diameter not found in 'End Mill'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #5: Tool diameter not found in 'Chamfer Mill 10'\n",
            "Setup 1, Step 1: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 1, Step 4: 'Contour Milling' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Face Milling'.\n",
            "Setup 2, Step 5: 'Chamfering' appears before any 'Slot Milling'.\n",
            "Setup 2, Step 5: Chamfering should be last in its setup.\n",
            "â Step #6: Unknown operation 'Fillet Milling'\n",
            "ð Loop 2/3\n",
            "ð Loop 3/3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post-Processing"
      ],
      "metadata": {
        "id": "N1Q25LtEVLI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from typing import List, Dict\n",
        "\n",
        "\n",
        "def parse_full_plan_json(text: str) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Dato un JSON come stringa, restituisce una lista ordinata di dizionari:\n",
        "    - Setup #1\n",
        "    - Tutti gli step associati a Setup #1\n",
        "    - Setup #2\n",
        "    - Tutti gli step associati a Setup #2\n",
        "    - ...\n",
        "    \"\"\"\n",
        "    data = json.loads(text)\n",
        "\n",
        "    setup_plan = data.get(\"Setup plan\", [])\n",
        "    process_plan = data.get(\"Process plan\", [])\n",
        "\n",
        "    result: List[Dict] = []\n",
        "\n",
        "    for setup in sorted(setup_plan, key=lambda x: x[\"Setup number\"]):\n",
        "        # Aggiungi prima il setup\n",
        "        setup_entry = {\n",
        "            \"Type\": \"Setup\",\n",
        "            **setup\n",
        "        }\n",
        "        result.append(setup_entry)\n",
        "\n",
        "        # Aggiungi tutti gli step associati a questo setup\n",
        "        for step in sorted(process_plan, key=lambda x: x[\"Step number\"]):\n",
        "            if step[\"Setup number\"] == setup[\"Setup number\"]:\n",
        "                step_entry = {\n",
        "                    \"Type\": \"Step\",\n",
        "                    **step\n",
        "                }\n",
        "                result.append(step_entry)\n",
        "\n",
        "    return result\n",
        "\n",
        "def plan_to_dataframe(plan_list: List[Dict]) -> pd.DataFrame:\n",
        "\n",
        "    df = pd.DataFrame(plan_list)\n",
        "    df.fillna(\"-\", inplace=True)  # Rimpiazza NaN con \"-\"\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "# Esempio di utilizzo:\n",
        "plan_list = parse_full_plan_json(response_2)  # `response` Ã¨ la stringa JSON dell'LLM\n",
        "df_steps = plan_to_dataframe(plan_list)\n",
        "df_steps  # Per notebook Jupyter, mostra la tabella"
      ],
      "metadata": {
        "id": "R3gRYTFVVQoT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "77357e54-c9a3-4d8a-8a06-48f6445d0bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-e64dd9d04b61>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mparse_full_plan_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m     ) from _err\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m from pandas._config import (\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0mget_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mset_option\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_config/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;34m\"warn_copy_on_write\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdates\u001b[0m  \u001b[0;31m# pyright: ignore[reportUnusedImport]  # noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m from pandas._config.config import (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m from pandas._typing import (\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/_typing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBitGenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# These were moved in 1.25 and may be deprecated eventually:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;34m\"ModuleDeprecationWarning\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"VisibleDeprecationWarning\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;34m\"ComplexWarning\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TooHardError\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"AxisError\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         }\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpublic_symbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/random/_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPCG64DXSM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}